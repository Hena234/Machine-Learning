{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>sentence</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ b...</td>\n",
       "      <td>sentence</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Born and raised in Houston, Texas, she perform...</td>\n",
       "      <td>sentence</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Managed by her father, Mathew Knowles, the gro...</td>\n",
       "      <td>sentence</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Their hiatus saw the release of Beyoncé's debu...</td>\n",
       "      <td>sentence</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Following the disbandment of Destiny's Child i...</td>\n",
       "      <td>sentence</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                           sentence     label\n",
       "0           0  Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ b...  sentence\n",
       "1           1  Born and raised in Houston, Texas, she perform...  sentence\n",
       "2           2  Managed by her father, Mathew Knowles, the gro...  sentence\n",
       "3           3  Their hiatus saw the release of Beyoncé's debu...  sentence\n",
       "4           4  Following the disbandment of Destiny's Child i...  sentence"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sklearn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "df = pd.read_csv('nlp dataset.csv')\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from pprint import pprint\n",
    "import nltk, spacy, gensim\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "def preprocess_text(sen):\n",
    "    # Remove punctuations and numbers\n",
    "    sentence = re.sub('[^a-zA-Z]', ' ', sen)\n",
    "\n",
    "    # Single character removal\n",
    "    sentence = re.sub(r\"\\s+[a-zA-Z]\\s+\", ' ', sentence)\n",
    "\n",
    "    # Removing multiple spaces\n",
    "    sentence = re.sub(r'\\s+', ' ', sentence)\n",
    "\n",
    "    return sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_lemmatized = df.sentence.apply(preprocess_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         Beyonc Giselle Knowles Carter bi nse bee YON s...\n",
       "1         Born and raised in Houston Texas she performed...\n",
       "2         Managed by her father Mathew Knowles the group...\n",
       "3         Their hiatus saw the release of Beyonc debut a...\n",
       "4         Following the disbandment of Destiny Child in ...\n",
       "                                ...                        \n",
       "235105                                        hi teensUser \n",
       "235106                                                 JOIN\n",
       "235107                                        Hi teensUser \n",
       "235108                          Not that know of teensUser \n",
       "235109                                                  Uh \n",
       "Name: sentence, Length: 235110, dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_lemmatized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "sentences_train, sentences_test, y_train, y_test = train_test_split(data_lemmatized,df.label, test_size=0.25, random_state=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "vectorizer = CountVectorizer()\n",
    "vectorizer.fit(sentences_train)\n",
    "X_train = vectorizer.transform(sentences_train)\n",
    "X_test  = vectorizer.transform(sentences_test)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 39651)\t0.18213474082870504\n",
      "  (0, 59547)\t0.16700603471983885\n",
      "  (0, 2570)\t0.062621848222198\n",
      "  (0, 48995)\t0.21961724312437506\n",
      "  (0, 71263)\t0.20123977067131815\n",
      "  (0, 63943)\t0.0389928684480599\n",
      "  (0, 45273)\t0.09222461088152092\n",
      "  (0, 52598)\t0.2381105231428315\n",
      "  (0, 20152)\t0.30811122009848424\n",
      "  (0, 9092)\t0.1276298731310181\n",
      "  (0, 51763)\t0.1923255030139485\n",
      "  (0, 28998)\t0.149516248463318\n",
      "  (0, 44981)\t0.04962800771497838\n",
      "  (0, 6052)\t0.10618822363669338\n",
      "  (0, 45309)\t0.1368834238887918\n",
      "  (0, 44299)\t0.11263197850773331\n",
      "  (0, 42435)\t0.3442078432766714\n",
      "  (0, 70493)\t0.15180738342315622\n",
      "  (0, 3989)\t0.19298424170951936\n",
      "  (0, 21217)\t0.17422548664526105\n",
      "  (0, 17590)\t0.1940042984667248\n",
      "  (0, 63931)\t0.09141598571349249\n",
      "  (0, 4225)\t0.24615677240712125\n",
      "  (0, 63941)\t0.30223179467055905\n",
      "  (0, 34105)\t0.31569111780097064\n",
      "  :\t:\n",
      "  (176330, 32170)\t0.23848437558390165\n",
      "  (176330, 15931)\t0.23320174389324014\n",
      "  (176330, 33661)\t0.2692269538371488\n",
      "  (176330, 44874)\t0.2892622530870145\n",
      "  (176330, 45285)\t0.1810960450971644\n",
      "  (176330, 23049)\t0.3133653962769659\n",
      "  (176330, 4382)\t0.16001847817849876\n",
      "  (176330, 41853)\t0.18205504741790415\n",
      "  (176330, 69847)\t0.15517183669695986\n",
      "  (176330, 63943)\t0.05854658835279556\n",
      "  (176330, 45273)\t0.13847240647272271\n",
      "  (176330, 30999)\t0.16371014378645604\n",
      "  (176331, 52881)\t0.40524625157596716\n",
      "  (176331, 35900)\t0.46085923059148987\n",
      "  (176331, 55426)\t0.4365267597989957\n",
      "  (176331, 54189)\t0.3563185117414584\n",
      "  (176331, 65482)\t0.3229689209906012\n",
      "  (176331, 60836)\t0.249007427544466\n",
      "  (176331, 45912)\t0.22101547952284253\n",
      "  (176331, 69816)\t0.10187579009549363\n",
      "  (176331, 9151)\t0.16628396183503566\n",
      "  (176331, 2570)\t0.11567241519590084\n",
      "  (176331, 63943)\t0.1440519370427746\n",
      "  (176331, 44981)\t0.09167074554208768\n",
      "  (176331, 30999)\t0.10070084350552974\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "tfidf_vectorizer = TfidfVectorizer(use_idf=True)\n",
    "X_train_vectors_tfidf = tfidf_vectorizer.fit_transform(sentences_train) \n",
    "X_test_vectors_tfidf = tfidf_vectorizer.transform(sentences_test)\n",
    "print(X_train_vectors_tfidf)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 6.90336098e-04, -7.38972246e-05, -4.59608076e-04, ...,\n",
       "         3.90531149e-04, -6.61622245e-05, -3.66857348e-04],\n",
       "       [ 1.51037036e-04, -1.77582815e-05, -1.85547242e-04, ...,\n",
       "         3.76893272e-04, -1.03863678e-04,  5.45549359e-05],\n",
       "       [-1.85831754e-31, -1.30450429e-21, -2.85028635e-19, ...,\n",
       "        -4.16065729e-17,  8.65419944e-17, -4.44517406e-17],\n",
       "       ...,\n",
       "       [ 4.22525435e-05, -2.05869732e-05,  1.49376524e-04, ...,\n",
       "        -1.64320139e-04,  4.92998533e-05, -1.14395874e-05],\n",
       "       [ 9.92078085e-06, -3.34809920e-06, -1.17328649e-05, ...,\n",
       "         7.30818492e-05,  2.91996033e-04,  8.26666698e-06],\n",
       "       [ 1.27995435e-07, -2.64060100e-08, -3.48594650e-07, ...,\n",
       "        -6.13941414e-07,  3.78206085e-06,  2.73265151e-07]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.decomposition import TruncatedSVD\n",
    "lsa_obj = TruncatedSVD(n_components=20, n_iter=100, random_state=42)\n",
    "tfidf_lsa_data = lsa_obj.fit_transform(X_train_vectors_tfidf)\n",
    "Sigma = lsa_obj.singular_values_\n",
    "V_T = lsa_obj.components_.T\n",
    "V_T\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LDA Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "FILTER_REGEX = re.compile(r\"[a-zA-Z0-9]{3,}\")\n",
    "\n",
    "def tokenize_line(line):\n",
    "    res = line.lower().split()\n",
    "    tokens=[]\n",
    "    for word in res:\n",
    "        if re.findall(FILTER_REGEX,word):\n",
    "            tokens.append(word)\n",
    "    return tokens\n",
    "    \n",
    "def tokenize(lines):\n",
    "    tokens = [tokenize_line(line) for line in lines]\n",
    "    return tokens\n",
    "    \n",
    "    \n",
    "d = [one for one in tokenize(data_lemmatized)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nltk_stopwords():\n",
    "    return set(nltk.corpus.stopwords.words('english'))\n",
    "\n",
    "from gensim.corpora import Dictionary\n",
    "dictionary = Dictionary(d)\n",
    "stopwords = nltk_stopwords()\n",
    "stopword_ids = map(dictionary.token2id.get, stopwords)\n",
    "dictionary.filter_tokens(stopword_ids)\n",
    "dictionary.compactify()\n",
    "dictionary.filter_extremes(no_below=10, no_above=1, keep_n=None)\n",
    "dictionary.compactify()\n",
    "corpus = [dictionary.doc2bow(doc) for doc in d]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim import models\n",
    "lda = models.ldamodel.LdaModel(corpus=corpus, id2word=dictionary, num_topics=10, passes=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<link rel=\"stylesheet\" type=\"text/css\" href=\"https://cdn.jsdelivr.net/gh/bmabey/pyLDAvis@3.4.0/pyLDAvis/js/ldavis.v1.0.0.css\">\n",
       "\n",
       "\n",
       "<div id=\"ldavis_el1404427492905800009913921335\" style=\"background-color:white;\"></div>\n",
       "<script type=\"text/javascript\">\n",
       "\n",
       "var ldavis_el1404427492905800009913921335_data = {\"mdsDat\": {\"x\": [2.069129705429077, 0.6057055592536926, 7.30780553817749, 12.630254745483398, 12.491950988769531, 6.506008148193359, 6.731351852416992, 6.932595252990723, 0.8124479651451111, -3.4556190967559814], \"y\": [-3.2102975845336914, 2.469101667404175, -11.932613372802734, 0.13360697031021118, -6.297602653503418, -6.227632522583008, 4.846994400024414, -0.8467415571212769, -9.30708122253418, -3.724640369415283], \"topics\": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10], \"cluster\": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1], \"Freq\": [12.101067623296927, 11.668697105681865, 11.267092542163587, 11.224661587974547, 10.356521636855948, 9.674721011367131, 9.517605208028318, 9.058855518129405, 8.095582851199598, 7.03519491530268]}, \"tinfo\": {\"Term\": [\"suser\", \"part\", \"join\", \"lol\", \"adultsuser\", \"type\", \"action\", \"much\", \"year\", \"name\", \"teensuser\", \"used\", \"hey\", \"called\", \"get\", \"chat\", \"population\", \"like\", \"war\", \"university\", \"term\", \"kind\", \"percentage\", \"period\", \"know\", \"language\", \"located\", \"many\", \"eisenhower\", \"take\", \"type\", \"like\", \"good\", \"see\", \"religion\", \"portugal\", \"early\", \"anthropology\", \"need\", \"got\", \"way\", \"modern\", \"greek\", \"seen\", \"dont\", \"important\", \"anyone\", \"thought\", \"humanism\", \"era\", \"quran\", \"iran\", \"process\", \"example\", \"art\", \"nice\", \"even\", \"whats\", \"really\", \"create\", \"say\", \"well\", \"century\", \"considered\", \"one\", \"groups\", \"used\", \"two\", \"form\", \"time\", \"part\", \"states\", \"witnesses\", \"empire\", \"jehovah\", \"united\", \"south\", \"party\", \"north\", \"right\", \"court\", \"rule\", \"china\", \"west\", \"premier\", \"east\", \"council\", \"majority\", \"river\", \"punjab\", \"position\", \"constitution\", \"kingdom\", \"armenian\", \"central\", \"chinese\", \"dynasty\", \"languages\", \"lived\", \"status\", \"law\", \"members\", \"church\", \"state\", \"america\", \"great\", \"leader\", \"many\", \"country\", \"people\", \"region\", \"war\", \"teensuser\", \"take\", \"eisenhower\", \"dame\", \"notre\", \"police\", \"led\", \"san\", \"place\", \"french\", \"genocide\", \"rome\", \"away\", \"army\", \"france\", \"japan\", \"mode\", \"federal\", \"japanese\", \"took\", \"lost\", \"capital\", \"leave\", \"someone\", \"put\", \"germany\", \"paris\", \"forces\", \"teens\", \"end\", \"financial\", \"never\", \"government\", \"world\", \"year\", \"organization\", \"many\", \"created\", \"countries\", \"years\", \"first\", \"people\", \"chat\", \"want\", \"league\", \"red\", \"wanna\", \"richmond\", \"game\", \"music\", \"live\", \"youtube\", \"football\", \"species\", \"talk\", \"girls\", \"guys\", \"play\", \"popular\", \"song\", \"team\", \"percent\", \"college\", \"washington\", \"home\", \"miami\", \"stand\", \"mary\", \"rank\", \"women\", \"played\", \"season\", \"many\", \"first\", \"american\", \"year\", \"new\", \"held\", \"name\", \"kind\", \"think\", \"roman\", \"windows\", \"happened\", \"island\", \"types\", \"thanks\", \"always\", \"leds\", \"battle\", \"translation\", \"responsible\", \"player\", \"run\", \"food\", \"standard\", \"antibiotics\", \"open\", \"originally\", \"systems\", \"available\", \"market\", \"production\", \"data\", \"related\", \"religions\", \"added\", \"typically\", \"antenna\", \"developed\", \"used\", \"use\", \"usually\", \"service\", \"company\", \"made\", \"system\", \"first\", \"many\", \"using\", \"power\", \"one\", \"action\", \"called\", \"get\", \"percentage\", \"begin\", \"color\", \"energy\", \"namibia\", \"human\", \"amount\", \"schools\", \"portuguese\", \"social\", \"bacteria\", \"gaddafi\", \"big\", \"birds\", \"associated\", \"effect\", \"science\", \"animals\", \"level\", \"lose\", \"private\", \"class\", \"discovered\", \"supreme\", \"islamic\", \"similar\", \"produce\", \"field\", \"age\", \"system\", \"white\", \"students\", \"work\", \"study\", \"start\", \"terms\", \"found\", \"many\", \"people\", \"often\", \"much\", \"population\", \"located\", \"believe\", \"force\", \"everyone\", \"air\", \"largest\", \"mean\", \"neptune\", \"average\", \"rate\", \"culture\", \"sea\", \"hot\", \"minority\", \"thats\", \"charleston\", \"tucson\", \"per\", \"native\", \"disease\", \"highest\", \"aircraft\", \"street\", \"total\", \"side\", \"days\", \"americans\", \"station\", \"area\", \"bronx\", \"high\", \"large\", \"water\", \"city\", \"many\", \"non\", \"people\", \"number\", \"around\", \"university\", \"term\", \"know\", \"language\", \"president\", \"english\", \"word\", \"diego\", \"founded\", \"russian\", \"today\", \"old\", \"universities\", \"armenia\", \"published\", \"model\", \"research\", \"report\", \"receive\", \"architecture\", \"born\", \"spanish\", \"purpose\", \"vote\", \"sure\", \"ever\", \"election\", \"decline\", \"oldest\", \"santa\", \"another\", \"name\", \"school\", \"last\", \"given\", \"year\", \"book\", \"long\", \"still\", \"allowed\", \"general\", \"first\", \"used\", \"public\", \"join\", \"period\", \"come\", \"greece\", \"british\", \"hunting\", \"european\", \"military\", \"caused\", \"egypt\", \"crisis\", \"airport\", \"stop\", \"africa\", \"die\", \"occur\", \"theory\", \"pain\", \"something\", \"union\", \"low\", \"ancient\", \"india\", \"believed\", \"money\", \"christian\", \"happens\", \"museum\", \"names\", \"congress\", \"back\", \"europe\", \"time\", \"known\", \"date\", \"many\", \"first\", \"suser\", \"lol\", \"adultsuser\", \"hey\", \"whitehead\", \"room\", \"yes\", \"lmao\", \"hello\", \"god\", \"common\", \"cause\", \"formed\", \"call\", \"tuvalu\", \"yeah\", \"land\", \"hiya\", \"wrote\", \"man\", \"give\", \"find\", \"change\", \"event\", \"besides\", \"movement\", \"mosaic\", \"makes\", \"write\", \"ireland\", \"love\", \"make\", \"must\", \"would\", \"could\", \"name\"], \"Freq\": [24117.0, 27323.0, 23154.0, 8542.0, 7271.0, 8877.0, 8020.0, 6576.0, 12562.0, 7591.0, 5640.0, 8566.0, 3605.0, 4007.0, 3921.0, 3985.0, 3697.0, 4086.0, 3914.0, 3261.0, 3240.0, 3371.0, 3263.0, 2931.0, 2949.0, 2904.0, 2938.0, 21142.0, 3035.0, 3034.0, 8875.417081723248, 4084.3987989742677, 3074.9584223059514, 2121.2740208098885, 2110.0573819519723, 1970.6557139095883, 1960.1975542775003, 1769.7339957821514, 1627.268320549791, 1567.697611035584, 1498.5036198429482, 1435.9037874710984, 1434.4840359455056, 1408.1281068596227, 1504.841042217875, 1382.181609674288, 1372.7442757673334, 1345.9117981415002, 1226.4133757120105, 1191.849428430535, 1150.4751822691646, 1098.6430824786216, 1096.620199207154, 1094.869862532165, 1077.2589867580646, 1074.0264739627803, 1020.5787807809113, 1002.3226468596093, 974.4669974862926, 963.4244742871293, 1891.1626846007723, 1806.5691987012715, 2555.7275757326356, 1810.1598369083208, 2795.4263912791016, 1322.9514814047075, 1704.3276066729868, 1361.8864763279842, 1120.6564221938177, 1126.1930349396457, 27321.126884606016, 2949.4593087171024, 2300.304164888686, 2296.735594997367, 2122.648752273726, 2028.4136032815836, 1882.744308854052, 1744.2896591172218, 1643.1067065708958, 1519.7624648554936, 1483.6101627902058, 1447.6944080648836, 1195.9982026935404, 1190.9586132527324, 1150.5527867532905, 1143.868283502262, 1137.53343754586, 1110.1300429388907, 1038.8097904833148, 995.8661700272054, 966.1009412104287, 945.1372405700085, 928.9888765907203, 911.0770792400234, 905.301783311506, 874.6263636073949, 856.1094771775017, 829.6745988518793, 828.6067425233954, 819.6475489058894, 1494.8735537188836, 1419.0644097669758, 2054.246933361373, 2624.480245642088, 1063.66280150388, 1432.4586938849877, 1152.8648525830474, 3282.850408298509, 1415.0923815852045, 1388.0951992501925, 996.7859998498066, 3912.3439833561997, 5637.36546473449, 3032.4268987990085, 3033.595615885653, 2986.1743455185624, 2970.200549069251, 2878.410386619219, 2359.9666892246923, 2172.0892918963573, 2037.4866273858072, 1503.2390372367522, 1365.2694494240961, 1220.8909118992656, 1197.9551477306666, 1167.6814243795898, 1061.514408257097, 1049.227208579227, 1028.0467993523189, 998.524774013658, 991.1334409483022, 955.1715052465447, 870.4417008052335, 816.5691235164246, 814.048394691972, 813.1591782055223, 801.6365926398391, 784.4950763027626, 764.4413118669207, 716.9242629217478, 716.6347903327593, 1753.1673722633943, 1291.9072373512142, 1637.0561939443091, 1623.6173720177271, 2407.262597446945, 3766.6739308255774, 923.9846326359127, 3539.8349285949603, 1348.9502422772284, 1227.0721203816518, 1239.5381510585592, 1532.662862228624, 1185.2333592840264, 3983.7308019578145, 2724.9381526039183, 2410.3136470056493, 2271.05065434195, 2483.536488931209, 2101.440517031766, 1938.2576753871047, 1928.1712907418905, 1823.3030154234193, 1840.532542743008, 1753.238945403429, 1722.0663911210436, 1603.9557976618162, 1505.365139186768, 1507.53661747122, 1471.5791661787, 1378.3715523201786, 1354.8814386173299, 1291.2317968040722, 1191.2378284115914, 1172.3988279929301, 1147.4838324564423, 1115.5378114416535, 1057.708234775439, 1043.178130005356, 1038.973404004775, 973.8661440288981, 969.9151718847459, 947.7403773884876, 940.529964396469, 5980.272578070151, 3511.6002747692232, 1446.3615961333162, 2822.6216552342835, 1429.41335524742, 1095.0543308669178, 1354.7462356863691, 3369.182243441992, 2366.3995494429428, 2266.8962069809318, 2188.2897903264097, 1998.1153694407305, 1627.2540357761877, 1549.6185256670362, 1409.6426444358256, 1370.5901503324724, 1353.5217669058804, 1130.8879725557335, 1094.9557007731134, 1070.3328927265513, 1029.9464278517712, 988.7210480425354, 960.409545869499, 915.0112408056489, 824.7797852342094, 822.7018776187208, 823.5938685448672, 819.9977955157349, 818.3991431541652, 803.383002307606, 791.985893348427, 790.7729148870056, 782.831157742147, 766.969205574054, 760.5600176892682, 754.8738155991923, 752.9144560046184, 1286.67159511484, 5248.234021561858, 2977.0512298835793, 1250.7118250799458, 878.3556340441631, 989.7447686914802, 1219.8208122515268, 1217.8907841260454, 1546.8489715348264, 1759.4036525220909, 869.617387839786, 931.0344287577105, 949.2414144205255, 8018.8424849227285, 4005.051190305924, 3919.4213932375806, 3261.190809203375, 2198.7070777537724, 1754.4877043035292, 1727.7947328971081, 1566.7732996902353, 1276.438183873152, 1096.9515922435667, 1067.56334215928, 1030.8245841052474, 980.5459874768285, 966.2099036750461, 895.7909674009348, 882.8004434365183, 869.5035395745876, 834.7242428400839, 797.1394130701317, 791.2007643406471, 778.1935228146148, 753.8131202486798, 746.6303587386586, 745.2569091155729, 744.965044954486, 740.1562587429835, 728.7619764910881, 722.0642689151671, 705.5038523785973, 703.7802310014722, 997.960630637423, 1093.4009452545417, 2153.3426287495763, 998.502932026422, 1054.9214405163627, 1410.8051368398603, 1069.17189778304, 1023.7537894835111, 807.21439428876, 971.737218839702, 1273.3621525358524, 1027.6977476904522, 848.6109096561861, 6574.575804664337, 3695.8067087730974, 2936.8425001467226, 2208.8710332104465, 1830.8982771183314, 1684.4634210160177, 1681.2271550843682, 1664.6384442064648, 1498.6638904629906, 1292.163489410729, 1232.0426696162865, 1229.4454739476892, 1212.4965539960845, 1184.8942701841063, 1146.289805350852, 1116.8685860537898, 1026.7437142405838, 1014.1334283457352, 1001.290009362206, 968.5987495187887, 961.537528527913, 906.7197243659418, 884.8434010052665, 832.8341846965704, 821.8071340065088, 795.4648599298426, 789.8719120941739, 764.8451632715283, 721.1838123020422, 717.5222750341587, 2508.4853995897297, 1440.6766475761392, 1451.2504284963986, 1274.0497062631018, 1035.7880105305287, 1868.6319826451372, 3279.7438888679, 1276.3518353452687, 1703.9333231351027, 1064.912719195876, 1006.4572045132128, 3259.4629431622657, 3238.44650123976, 2947.118830675588, 2902.882257945825, 2166.2941322385304, 1775.271148923974, 1717.9083484033463, 1555.0810906417405, 1516.3952788193974, 1445.8828849916636, 1421.159267207942, 1396.0588995642977, 1277.7153086846051, 1062.515162562096, 1034.0036586208596, 932.7188035449767, 926.9422523384504, 897.2723991116394, 886.2503658667589, 777.988537097961, 761.133295087563, 751.3096990237698, 738.8979520677847, 714.9091263193355, 707.4529304697779, 698.5989269721169, 698.1003862677322, 638.776638614419, 629.7977899564472, 580.0221008984371, 1848.2146254513862, 5611.842337486181, 1971.9704640147656, 1873.0170445840013, 1032.6150139203019, 5015.199146066088, 1186.8235268624837, 1900.5912553492042, 1076.0605952031785, 942.4766554601292, 946.2856927548954, 1892.3717859690862, 1612.6899163039714, 944.5293847840647, 23152.677155712663, 2929.361160238623, 2209.0394923041267, 2020.6185704128525, 1838.1151448364506, 1636.7081852286058, 1462.1834646398672, 1372.7101124165076, 1251.8911848544403, 1122.2220798833298, 1093.4776835619732, 1065.267252607252, 1025.8225997688373, 1014.7331115008159, 994.3917264482392, 946.0797683660176, 941.8533557209155, 928.6948796041552, 905.5095233585741, 800.206708132724, 752.1554206831602, 750.1840819640896, 747.4197449669783, 742.2789379560089, 738.9888924369094, 724.5872494128824, 719.708477802281, 711.2420048349744, 697.517354833617, 658.4727154110765, 1610.8435170142623, 979.7268879712905, 1231.2227332201023, 939.8639338296841, 800.8611824881743, 1058.138047280834, 747.835384973135, 24114.898808810376, 8539.602993609336, 7266.755657239697, 3603.6363653865737, 1324.3789252776753, 1245.9926108446152, 1036.419011242546, 1107.1055399116367, 997.9995448000411, 952.8757071204911, 950.0579356397408, 911.012258223548, 783.2385937647985, 779.6017667945997, 762.2792057349609, 805.9094472218712, 701.0928193791923, 692.6734246980161, 689.8501975913587, 684.6321286123166, 670.8391796137452, 664.3784139335098, 662.5825049052773, 627.3837553569894, 622.1612388568274, 596.9409476932407, 541.2728676422511, 514.5332439638108, 509.4367998623287, 493.66885498509515, 802.2458165243896, 1453.6897123357583, 605.7651260966131, 692.3583623018794, 630.4217680835992, 623.5397332028829], \"Total\": [24117.0, 27323.0, 23154.0, 8542.0, 7271.0, 8877.0, 8020.0, 6576.0, 12562.0, 7591.0, 5640.0, 8566.0, 3605.0, 4007.0, 3921.0, 3985.0, 3697.0, 4086.0, 3914.0, 3261.0, 3240.0, 3371.0, 3263.0, 2931.0, 2949.0, 2904.0, 2938.0, 21142.0, 3035.0, 3034.0, 8877.508750197234, 4086.4905790756598, 3077.0502618965565, 2123.3657582870533, 2112.149084755901, 1972.7496988772605, 1962.2892084669406, 1771.8317446487076, 1629.3600913612656, 1569.789667577606, 1500.5953064432028, 1437.995404996216, 1436.5757273925572, 1410.2198194009213, 1507.1169488494181, 1384.273230270065, 1374.83674572069, 1348.003456178027, 1228.5060864913937, 1193.9411100785867, 1152.5729544654246, 1100.738322053898, 1098.711836067462, 1096.9614896257845, 1079.3506329855686, 1076.1188803759533, 1022.6705016010782, 1004.4148390731924, 976.5589729036222, 965.5161575816513, 2186.0468929022263, 2603.848311025079, 4602.8752652862895, 2690.8626727985047, 7228.6256917445035, 1695.5582124527516, 8566.814468488034, 4156.798770842635, 1903.0822628167805, 4640.42135132967, 27323.213782019837, 2951.546154810476, 2302.3941614885516, 2298.822432915911, 2124.74391053179, 2030.500431930674, 1884.8311870980963, 1746.376511156991, 1645.1935696759515, 1521.849517367055, 1485.697046175683, 1449.781261931696, 1198.085077652289, 1193.045470236024, 1152.646955649996, 1145.9551368022505, 1139.6203404700013, 1112.2169440901555, 1040.8966764927427, 997.9654589811868, 968.1878322967556, 947.2240923196669, 931.0757017531128, 913.1650751787823, 907.3887087504112, 876.7132436319566, 858.196306486585, 831.7614777609405, 830.6936654550991, 821.7344791592648, 1710.650451908596, 1614.875442441019, 2566.398721849353, 4095.4719128535735, 1180.766266060134, 2078.8769737305684, 1549.5812600405998, 21142.667143729486, 3680.3626007925836, 6713.756398924248, 1292.51236924077, 3914.4263286076007, 5640.568528336523, 3034.509317660338, 3035.6914190769153, 2988.2603487280544, 2972.286842989934, 2880.4938427367156, 2362.049214411197, 2174.172977316676, 2039.5690217270217, 1505.3214159343806, 1367.352704245565, 1222.9735344066924, 1200.0376917892836, 1169.7638093317983, 1063.5967786574663, 1051.3096197791751, 1030.1293959128006, 1000.6071932564125, 993.2158850492157, 957.2538919393284, 872.5241484565662, 818.6514810140228, 816.1308573796424, 815.2419134409431, 803.7190550517662, 786.5774527754601, 766.5237391627708, 719.0066129261795, 718.717313964695, 2177.6369949891287, 1545.233427488193, 2285.92758712265, 2404.48786797252, 4454.950103521458, 12562.19317560932, 1072.4605957092917, 21142.667143729486, 2568.9859186123613, 2078.6345963154236, 2540.914690563069, 9737.512732874771, 6713.756398924248, 3985.8053920600714, 2727.012397660596, 2412.387821469215, 2273.1251043548446, 2485.8690412485685, 2103.5322019453747, 1940.3318019590365, 1930.245371360549, 1825.3771771568922, 1842.6352351310302, 1755.3130112461756, 1724.140532571271, 1606.0301850624442, 1507.4393306161553, 1509.6370489149806, 1473.6532607465695, 1380.4456473516575, 1356.9555929466658, 1293.3058458563173, 1193.3120546062519, 1174.4729663178068, 1149.5584019669711, 1117.6119303098662, 1059.7829388085042, 1045.2521690405504, 1041.0478677325007, 975.9402835679152, 971.9892878903859, 949.8144350618855, 942.6040387454093, 21142.667143729486, 9737.512732874771, 2040.7998645031666, 12562.19317560932, 4705.048227683185, 1363.966188593509, 7591.8223950118845, 3371.22120983591, 2368.438649914834, 2268.93532547659, 2190.3290036925064, 2000.1543373276893, 1629.2930110339737, 1551.657485623703, 1411.6821419451796, 1372.6291794068875, 1355.5784538802475, 1132.9269441716128, 1096.9950759014941, 1072.371860129644, 1031.9855413526261, 990.7601085002492, 962.4485802456476, 917.0501816233349, 826.8191026714642, 824.7408522504802, 825.6352791291775, 822.0367370595499, 820.4380801695964, 805.4219895985286, 794.0248620829689, 792.8118608563931, 784.8701736102167, 769.0083228864643, 762.5989905744344, 756.9128076273555, 754.9541829922294, 1411.0730088200364, 8566.814468488034, 5290.74464635574, 1569.2472560644621, 1008.6589875260806, 1470.2971832174608, 3353.8763417742007, 3373.0328302840494, 9737.512732874771, 21142.667143729486, 1157.5977229266657, 2327.1006933266895, 7228.6256917445035, 8020.922521696395, 4007.1309603199948, 3921.5012942383305, 3263.270627352955, 2200.786855046095, 1756.5675182438026, 1729.874495258974, 1568.9038411962829, 1278.5179746713275, 1099.0314212692037, 1069.6430947072242, 1032.9047003109224, 982.6258036671345, 968.2904466777834, 897.8743617740124, 884.8804079673872, 871.5834923463252, 836.8040239278095, 799.2191768889652, 793.2805588878541, 780.2733350254326, 755.8929220546978, 748.7101655497579, 747.3367336911268, 747.0448238334989, 742.2360082361299, 730.8418494269464, 724.144063419972, 707.5836267124636, 705.8599866375807, 1061.3394787129662, 1222.6141542214268, 3373.0328302840494, 1171.978272639989, 1451.5535209140721, 2844.1942130967855, 1646.4087198927507, 1566.6357401838086, 1021.9823150714652, 2513.1357109694072, 21142.667143729486, 6713.756398924248, 1814.5310339534938, 6576.636936353641, 3697.867768713236, 2938.9035517971806, 2210.932166043526, 1832.9594230671828, 1686.5248721412297, 1683.2882363751087, 1666.6994881900553, 1500.7249642710321, 1294.239231169678, 1234.103734071362, 1231.506549774474, 1214.5576861099157, 1186.9554332745404, 1148.3511342942293, 1118.9300849116587, 1028.8304226557248, 1016.210827372088, 1003.3523331509766, 970.6598024487423, 963.598619204462, 908.7810336138838, 886.904470081539, 834.8953145690361, 823.8682344042961, 797.5259232641134, 791.9330112616422, 766.9063267565266, 723.2449135522377, 719.5833839744781, 2906.586866947939, 1687.8414393404673, 1909.934045905177, 1913.171773130735, 1317.62251914844, 4404.868410423138, 21142.667143729486, 2310.279805093827, 6713.756398924248, 1682.0954203384383, 1642.2936315137342, 3261.533963672932, 3240.517477576555, 2949.1900616466137, 2904.9532277677954, 2168.365181089819, 1777.3421372049079, 1719.9793296221903, 1557.1565302776519, 1518.4662325650731, 1447.95404193794, 1423.2303699053896, 1398.1299187664117, 1279.7865849368573, 1064.5873527415674, 1036.0746060612134, 934.7897963278566, 929.0132794420829, 899.3434627983999, 888.3213739378244, 780.0595544143454, 763.2042485857579, 753.3806944897412, 740.9689442762382, 716.9801801886293, 709.5242698591143, 700.670089278133, 700.171363852622, 640.8477211464694, 631.8687728101305, 582.0936854054662, 2066.0229014492866, 7591.8223950118845, 2442.431252185572, 2498.4550403751336, 1158.874362385777, 12562.19317560932, 1527.427842900689, 3876.3766506508687, 1555.8770552176015, 1211.5029450045372, 1258.9775602995412, 9737.512732874771, 8566.814468488034, 1653.1335319948741, 23154.77782376728, 2931.46186369057, 2211.1402036255554, 2022.7196464903739, 1840.2158023561155, 1638.8111515600924, 1464.2841668688134, 1374.8108015972593, 1253.9918645697023, 1124.3229749798627, 1095.578787693807, 1067.367982869734, 1027.9233176999062, 1016.8338516820039, 996.4923564796579, 948.1804382606408, 943.954020360615, 930.7976980184253, 907.6104376699568, 802.3073495929679, 754.2561384656382, 752.2847682595889, 749.5203953187571, 744.379641732894, 741.0896231342689, 726.6880146177303, 721.809149703157, 713.3427153121604, 699.6181051737758, 660.5734824682382, 2319.491578159079, 1197.6098065109577, 4640.42135132967, 3165.9841424904725, 1306.2700058932376, 21142.667143729486, 9737.512732874771, 24117.395697292224, 8542.49590259697, 7271.041950405101, 3605.832302758661, 1326.5997182881722, 1248.180428250682, 1038.6071232311037, 1109.4588551102156, 1000.2051846993294, 955.0633433540978, 952.2455602489979, 913.1998957981792, 785.4262263587331, 781.7894281328884, 764.4873620903065, 808.3383534921388, 703.2804775205336, 694.869382514656, 692.0378132705197, 686.8198305474614, 673.0268481309292, 666.5660752695962, 664.7701348749739, 629.5713933008534, 624.348925658189, 599.1285769241055, 543.469444182742, 516.7208924697965, 511.62441266071374, 495.85655653192316, 917.2779455144903, 1990.9174949009284, 1048.1631455514898, 3763.785815823679, 1881.5576142896425, 7591.8223950118845], \"Category\": [\"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\"], \"logprob\": [30.0, 29.0, 28.0, 27.0, 26.0, 25.0, 24.0, 23.0, 22.0, 21.0, 20.0, 19.0, 18.0, 17.0, 16.0, 15.0, 14.0, 13.0, 12.0, 11.0, 10.0, 9.0, 8.0, 7.0, 6.0, 5.0, 4.0, 3.0, 2.0, 1.0, -3.206, -3.9821, -4.266, -4.6373, -4.6426, -4.7109, -4.7162, -4.8184, -4.9024, -4.9397, -4.9848, -5.0275, -5.0285, -5.047, -4.9806, -5.0656, -5.0725, -5.0922, -5.1852, -5.2138, -5.2491, -5.2952, -5.297, -5.2986, -5.3149, -5.3179, -5.3689, -5.387, -5.4151, -5.4265, -4.7521, -4.7978, -4.4509, -4.7959, -4.3613, -5.1094, -4.8561, -5.0804, -5.2754, -5.2704, -2.0452, -4.2713, -4.5199, -4.5214, -4.6002, -4.6456, -4.7202, -4.7965, -4.8563, -4.9343, -4.9584, -4.9829, -5.1739, -5.1781, -5.2127, -5.2185, -5.224, -5.2484, -5.3148, -5.357, -5.3874, -5.4093, -5.4266, -5.446, -5.4524, -5.4869, -5.5083, -5.5396, -5.5409, -5.5518, -4.9509, -5.0029, -4.633, -4.388, -5.2912, -4.9935, -5.2106, -4.1642, -5.0057, -5.025, -5.3561, -3.9537, -3.5885, -4.2085, -4.2081, -4.2239, -4.2292, -4.2606, -4.4592, -4.5422, -4.6062, -4.9102, -5.0065, -5.1183, -5.1373, -5.1629, -5.2582, -5.2698, -5.2902, -5.3193, -5.3268, -5.3637, -5.4566, -5.5205, -5.5236, -5.5247, -5.539, -5.5606, -5.5865, -5.6507, -5.6511, -4.7564, -5.0618, -4.825, -4.8332, -4.4394, -3.9917, -5.3969, -4.0538, -5.0185, -5.1132, -5.1031, -4.8909, -5.1479, -3.9319, -4.3117, -4.4343, -4.4939, -4.4044, -4.5715, -4.6523, -4.6575, -4.7134, -4.704, -4.7526, -4.7706, -4.8416, -4.9051, -4.9036, -4.9278, -4.9932, -5.0104, -5.0585, -5.1391, -5.155, -5.1765, -5.2048, -5.258, -5.2718, -5.2759, -5.3406, -5.3446, -5.3678, -5.3754, -3.5256, -4.058, -4.945, -4.2764, -4.9568, -5.2233, -5.0105, -4.0189, -4.3722, -4.4152, -4.4505, -4.5414, -4.7467, -4.7956, -4.8903, -4.9184, -4.9309, -5.1106, -5.1429, -5.1656, -5.2041, -5.2449, -5.274, -5.3224, -5.4262, -5.4288, -5.4277, -5.4321, -5.434, -5.4525, -5.4668, -5.4683, -5.4784, -5.4989, -5.5073, -5.5148, -5.5174, -4.9815, -3.5757, -4.1427, -5.0099, -5.3633, -5.2439, -5.0349, -5.0365, -4.7974, -4.6686, -5.3733, -5.3051, -5.2857, -3.0837, -3.7779, -3.7996, -3.9834, -4.3776, -4.6033, -4.6187, -4.7165, -4.9214, -5.073, -5.1001, -5.1351, -5.1851, -5.1999, -5.2756, -5.2902, -5.3053, -5.3462, -5.3922, -5.3997, -5.4163, -5.4481, -5.4577, -5.4595, -5.4599, -5.4664, -5.4819, -5.4911, -5.5143, -5.5168, -5.1675, -5.0762, -4.3985, -5.167, -5.112, -4.8213, -5.0986, -5.142, -5.3797, -5.1942, -4.9238, -5.1382, -5.3297, -3.2659, -3.8419, -4.0718, -4.3566, -4.5443, -4.6277, -4.6296, -4.6395, -4.7446, -4.8928, -4.9405, -4.9426, -4.9564, -4.9795, -5.0126, -5.0386, -5.1227, -5.1351, -5.1478, -5.181, -5.1884, -5.2471, -5.2715, -5.332, -5.3454, -5.378, -5.385, -5.4172, -5.476, -5.4811, -4.2294, -4.784, -4.7767, -4.9069, -5.114, -4.5239, -3.9614, -4.9051, -4.6162, -5.0862, -5.1427, -3.9182, -3.9246, -4.0189, -4.034, -4.3267, -4.5258, -4.5586, -4.6582, -4.6834, -4.731, -4.7483, -4.7661, -4.8547, -5.0391, -5.0663, -5.1694, -5.1756, -5.2081, -5.2205, -5.3508, -5.3727, -5.3857, -5.4023, -5.4353, -5.4458, -5.4584, -5.4591, -5.5479, -5.5621, -5.6444, -4.4855, -3.3748, -4.4207, -4.4722, -5.0676, -3.4873, -4.9284, -4.4576, -5.0264, -5.159, -5.1549, -4.4619, -4.6218, -5.1568, -1.8452, -3.9125, -4.1947, -4.2839, -4.3786, -4.4946, -4.6074, -4.6705, -4.7626, -4.872, -4.8979, -4.9241, -4.9618, -4.9727, -4.9929, -5.0427, -5.0472, -5.0613, -5.0866, -5.2102, -5.2721, -5.2747, -5.2784, -5.2853, -5.2898, -5.3095, -5.3162, -5.328, -5.3475, -5.4051, -4.5105, -5.0078, -4.7793, -5.0493, -5.2094, -4.9308, -5.2779, -1.6641, -2.7022, -2.8636, -3.565, -4.566, -4.627, -4.8111, -4.7452, -4.8489, -4.8952, -4.8981, -4.9401, -5.0912, -5.0959, -5.1184, -5.0627, -5.202, -5.2141, -5.2182, -5.2258, -5.2461, -5.2558, -5.2585, -5.3131, -5.3215, -5.3628, -5.4607, -5.5114, -5.5214, -5.5528, -5.0673, -4.4728, -5.3482, -5.2146, -5.3083, -5.3193], \"loglift\": [30.0, 29.0, 28.0, 27.0, 26.0, 25.0, 24.0, 23.0, 22.0, 21.0, 20.0, 19.0, 18.0, 17.0, 16.0, 15.0, 14.0, 13.0, 12.0, 11.0, 10.0, 9.0, 8.0, 7.0, 6.0, 5.0, 4.0, 3.0, 2.0, 1.0, 2.1116, 2.1114, 2.1112, 2.1109, 2.1109, 2.1108, 2.1108, 2.1107, 2.1106, 2.1105, 2.1105, 2.1104, 2.1104, 2.1104, 2.1104, 2.1104, 2.1104, 2.1103, 2.1102, 2.1101, 2.1101, 2.11, 2.11, 2.11, 2.1099, 2.1099, 2.1098, 2.1098, 2.1097, 2.1097, 1.967, 1.7463, 1.5235, 1.7154, 1.1618, 1.8637, 0.4972, 0.996, 1.5823, 0.6959, 2.1482, 2.1476, 2.1474, 2.1474, 2.1473, 2.1472, 2.1472, 2.1471, 2.147, 2.1469, 2.1469, 2.1468, 2.1465, 2.1465, 2.1464, 2.1464, 2.1464, 2.1464, 2.1463, 2.1462, 2.1461, 2.1461, 2.146, 2.146, 2.146, 2.1459, 2.1458, 2.1457, 2.1457, 2.1457, 2.0134, 2.019, 1.9257, 1.7033, 2.0438, 1.7758, 1.8525, 0.2857, 1.1924, 0.572, 1.8885, 2.1828, 2.1827, 2.1826, 2.1826, 2.1826, 2.1826, 2.1826, 2.1824, 2.1823, 2.1823, 2.1819, 2.1818, 2.1816, 2.1815, 2.1815, 2.1813, 2.1813, 2.1813, 2.1812, 2.1812, 2.1811, 2.1809, 2.1807, 2.1807, 2.1807, 2.1807, 2.1806, 2.1806, 2.1804, 2.1804, 1.9665, 2.0042, 1.8494, 1.7906, 1.5678, 0.9788, 2.0343, 0.3961, 1.5391, 1.6562, 1.4655, 0.3343, 0.4491, 2.1865, 2.1863, 2.1862, 2.1861, 2.1861, 2.1861, 2.186, 2.186, 2.1859, 2.1859, 2.1859, 2.1859, 2.1858, 2.1857, 2.1857, 2.1856, 2.1856, 2.1855, 2.1855, 2.1853, 2.1853, 2.1853, 2.1852, 2.1851, 2.1851, 2.1851, 2.1849, 2.1849, 2.1849, 2.1849, 0.9242, 1.1671, 1.8428, 0.694, 0.9957, 1.9675, 0.4636, 2.2669, 2.2667, 2.2667, 2.2666, 2.2665, 2.2663, 2.2662, 2.2661, 2.2661, 2.266, 2.2658, 2.2657, 2.2657, 2.2656, 2.2655, 2.2654, 2.2653, 2.2651, 2.2651, 2.2651, 2.2651, 2.2651, 2.265, 2.265, 2.265, 2.265, 2.2649, 2.2649, 2.2649, 2.2648, 2.1753, 1.7775, 1.6925, 2.0407, 2.1292, 1.8718, 1.2561, 1.2489, 0.4278, -0.2188, 1.9815, 1.3515, 0.2374, 2.3354, 2.3351, 2.3351, 2.335, 2.3347, 2.3345, 2.3345, 2.3343, 2.334, 2.3338, 2.3337, 2.3336, 2.3335, 2.3335, 2.3333, 2.3333, 2.3333, 2.3332, 2.333, 2.333, 2.333, 2.3329, 2.3329, 2.3329, 2.3329, 2.3328, 2.3328, 2.3328, 2.3327, 2.3327, 2.2741, 2.224, 1.8869, 2.1755, 2.0165, 1.6345, 1.9039, 1.9102, 2.0997, 1.3855, -0.474, 0.4588, 1.5757, 2.3517, 2.3515, 2.3513, 2.3511, 2.3509, 2.3508, 2.3508, 2.3508, 2.3507, 2.3504, 2.3504, 2.3504, 2.3503, 2.3503, 2.3502, 2.3502, 2.35, 2.35, 2.35, 2.3499, 2.3499, 2.3498, 2.3497, 2.3496, 2.3495, 2.3494, 2.3494, 2.3493, 2.3492, 2.3492, 2.2047, 2.1937, 2.0774, 1.9455, 2.1114, 1.4945, 0.4885, 1.7587, 0.9808, 1.8949, 1.8624, 2.4008, 2.4008, 2.4007, 2.4007, 2.4005, 2.4003, 2.4002, 2.4001, 2.4001, 2.4, 2.4, 2.3999, 2.3998, 2.3995, 2.3994, 2.3992, 2.3992, 2.3991, 2.3991, 2.3988, 2.3987, 2.3987, 2.3986, 2.3985, 2.3985, 2.3985, 2.3985, 2.3982, 2.3981, 2.3979, 2.29, 2.0992, 2.1875, 2.1133, 2.2861, 1.4832, 2.1491, 1.6887, 2.0327, 2.1503, 2.1159, 0.7633, 0.7314, 1.8417, 2.5138, 2.5131, 2.5129, 2.5128, 2.5127, 2.5126, 2.5124, 2.5123, 2.5122, 2.512, 2.5119, 2.5119, 2.5118, 2.5118, 2.5117, 2.5116, 2.5116, 2.5116, 2.5115, 2.5112, 2.5111, 2.5111, 2.511, 2.511, 2.511, 2.511, 2.5109, 2.5109, 2.5108, 2.5107, 2.1493, 2.313, 1.1871, 1.2994, 2.0246, -0.4809, -0.0527, 2.6541, 2.6539, 2.6537, 2.6536, 2.6526, 2.6525, 2.6521, 2.6521, 2.652, 2.652, 2.6519, 2.6518, 2.6515, 2.6514, 2.6514, 2.6512, 2.6511, 2.6511, 2.6511, 2.6511, 2.651, 2.651, 2.6509, 2.6508, 2.6507, 2.6506, 2.6502, 2.65, 2.65, 2.6498, 2.5202, 2.3398, 2.1059, 0.9612, 1.5608, 0.1548]}, \"token.table\": {\"Topic\": [6, 5, 1, 4, 6, 10, 9, 6, 10, 7, 7, 9, 3, 8, 5, 2, 4, 4, 7, 7, 6, 9, 6, 1, 8, 5, 1, 5, 1, 8, 2, 7, 8, 2, 3, 2, 3, 7, 9, 1, 6, 5, 7, 3, 1, 4, 9, 6, 5, 6, 7, 9, 10, 6, 6, 1, 8, 8, 9, 2, 7, 10, 6, 3, 10, 9, 2, 1, 2, 8, 9, 10, 7, 4, 2, 2, 9, 1, 2, 2, 3, 4, 7, 8, 6, 4, 6, 9, 10, 4, 5, 8, 9, 1, 2, 6, 2, 5, 6, 9, 10, 2, 1, 2, 3, 2, 3, 4, 7, 9, 2, 1, 1, 3, 4, 5, 9, 9, 7, 3, 5, 3, 9, 7, 8, 5, 6, 9, 8, 6, 7, 1, 2, 1, 2, 6, 9, 3, 8, 2, 2, 3, 6, 8, 1, 7, 9, 9, 1, 10, 8, 7, 1, 3, 4, 6, 3, 8, 10, 2, 3, 4, 5, 8, 9, 5, 4, 7, 3, 1, 2, 5, 6, 10, 5, 6, 7, 9, 10, 8, 3, 3, 6, 4, 8, 9, 3, 3, 6, 4, 10, 8, 10, 10, 1, 1, 2, 3, 1, 2, 9, 9, 1, 1, 6, 7, 4, 5, 9, 4, 8, 9, 10, 10, 6, 7, 7, 10, 4, 7, 6, 1, 9, 1, 9, 1, 10, 6, 5, 3, 3, 2, 9, 5, 2, 8, 1, 2, 4, 6, 8, 9, 10, 8, 2, 2, 5, 7, 7, 4, 8, 9, 2, 8, 2, 3, 4, 3, 3, 5, 6, 1, 4, 2, 10, 7, 10, 2, 3, 4, 5, 8, 6, 3, 4, 10, 9, 1, 2, 3, 4, 5, 9, 10, 2, 5, 10, 10, 10, 1, 2, 3, 4, 5, 6, 7, 9, 5, 4, 7, 2, 4, 4, 9, 7, 3, 8, 1, 9, 10, 10, 7, 9, 4, 6, 10, 4, 8, 10, 9, 6, 7, 1, 7, 1, 3, 2, 3, 4, 5, 7, 8, 1, 1, 7, 8, 2, 3, 1, 4, 5, 7, 9, 1, 5, 6, 8, 8, 1, 2, 4, 5, 7, 8, 10, 5, 3, 9, 5, 9, 3, 2, 2, 1, 2, 3, 6, 7, 9, 10, 7, 4, 6, 9, 3, 4, 4, 5, 3, 4, 7, 1, 6, 2, 2, 3, 5, 2, 8, 6, 1, 6, 5, 5, 6, 8, 8, 2, 8, 3, 1, 4, 7, 1, 8, 4, 2, 7, 5, 1, 5, 8, 8, 5, 4, 2, 2, 5, 3, 10, 2, 5, 8, 3, 8, 1, 6, 6, 8, 6, 6, 7, 4, 1, 1, 5, 7, 7, 6, 6, 3, 9, 4, 2, 8, 4, 4, 5, 3, 6, 2, 3, 8, 2, 7, 2, 1, 8, 9, 7, 4, 6, 1, 6, 6, 8, 10, 5, 6, 5, 3, 4, 4, 3, 3, 8, 6, 8, 5, 7, 9, 5, 1, 1, 3, 4, 5, 6, 7, 8, 9, 8, 3, 7, 5, 7, 10, 1, 2, 3, 4, 5, 7, 10, 1, 5, 5, 9, 2, 8, 8, 1, 5, 6, 8, 1, 5, 8, 5, 6, 5, 6, 8, 4, 4, 3, 4, 5, 7, 1, 1, 4, 6, 9, 2, 1, 6, 7, 10, 5, 2, 4, 8, 1, 6, 8, 10, 3, 4, 7, 8, 1, 2, 3, 4, 5, 6, 10, 10, 10, 10, 3, 4, 7, 8, 1, 3, 4, 8, 10, 4], \"Freq\": [0.9997603116485423, 0.9979032353908179, 0.00013753187051056495, 0.00013753187051056495, 0.00013753187051056495, 0.9994441030002755, 0.9981965080342571, 0.8939860513033514, 0.10387578089252116, 0.9986406152400635, 0.9977298775834974, 0.9977814747043775, 0.22038741308961496, 0.7775466034847089, 0.9988130957498722, 0.9011097543887764, 0.09739438134841098, 0.7085457154085166, 0.29057234387085085, 0.9968960534527485, 0.9981516258499163, 0.9969628944304234, 0.9970864888964089, 0.10454869587770735, 0.8944721758426073, 0.9974115210747172, 0.9989661858953369, 0.9977998782737523, 0.9986640263097367, 0.9973597472107221, 0.13624227250975635, 0.8628677258951234, 0.9985089502167392, 0.9976290429434586, 0.9984921662666194, 0.04993016987127874, 0.2508686583776444, 0.6125579376891026, 0.08585553599817441, 0.9978221785268551, 0.9978441500324752, 0.9970283191035058, 0.998295334489896, 0.9983019768435395, 0.16037997443183083, 0.14442820278135302, 0.6945487602410738, 0.9976345458269862, 0.9982991452524578, 0.9991880835520269, 0.999126085334864, 0.996803188051524, 0.9962377997916585, 0.9978749580729145, 0.9981832006225102, 0.2219417444664463, 0.7771234533382647, 0.9971118496918191, 0.9987959008105035, 0.14515581516693593, 0.8537531822675701, 0.9977111123935738, 0.9994682079669728, 0.9979826812113292, 0.9975910030122633, 0.998411580947229, 0.9973674912114558, 0.5553050762154472, 0.21443118553389923, 0.12296661703362408, 0.10710696501338635, 0.9973372226246192, 0.9978244402514337, 0.9995470446039167, 0.9982596581067724, 0.9980458335215068, 0.9976771123456353, 0.19872204410719654, 0.8003432913650622, 0.16368252869800023, 0.16572572253750373, 0.13961824569940381, 0.42430325400355406, 0.10647310119190308, 0.9972627829438591, 0.9978944033717864, 0.9985383321636452, 0.99903208144737, 0.9976418264965071, 0.10338046058646282, 0.6733332630302512, 0.22240401718271935, 0.9961041692763348, 0.6726467382735645, 0.1984493691923113, 0.12821167110739212, 0.9976519892835282, 0.29071658281721696, 0.24182092354997023, 0.1312742156414124, 0.3348289710691895, 0.9985781751935622, 0.22514779693822776, 0.18377448382564743, 0.5902913394085587, 0.38447298635609245, 0.21872844806830702, 0.08803480394302046, 0.16601625064563427, 0.14210556315493736, 0.9988577441275451, 0.997393976722302, 0.13507275282669987, 0.5251099238133088, 0.10081799130292585, 0.14324718455396412, 0.09536837015141635, 0.9976461869079856, 0.9978941419257675, 0.9992435904291216, 0.9977146395685403, 0.38583141136687193, 0.6131963502080644, 0.9975142638807154, 0.9971167547523397, 0.9120718715158556, 0.08716770800034983, 0.9974988704494806, 0.9986150844595775, 0.9969874700077626, 0.9980401949996676, 0.998595365242867, 0.9974407877661737, 0.9988333990437989, 0.998293880153366, 0.9972233187676958, 0.9979338899661778, 0.9994428224600543, 0.996898810827289, 0.999207231976765, 0.19424725102179471, 0.8050010190099436, 0.9989163981178337, 0.9986822249043219, 0.9983741994791863, 0.18035924457672992, 0.8182965726166449, 0.9984400795142805, 0.9983665299835451, 0.9959156446302753, 0.9976164398856334, 0.9985029143756272, 0.9982118883439987, 0.9983937820283082, 0.05841674717987908, 0.9403211884761181, 0.8361196289289258, 0.16243500531049562, 0.9961503062264931, 0.05186129290440585, 0.1574324000444637, 0.36066705085202644, 0.15887013885765516, 0.194300131039873, 0.07681633087622887, 0.9974558846094171, 0.9986822798946078, 0.9989310057590343, 0.9972091871060642, 0.5890444264562642, 0.19809968668511296, 0.09773618494278782, 0.11455101245982659, 0.9969109430302816, 0.229991558942531, 0.3867678119241179, 0.16513234768365115, 0.13727869867677023, 0.07997976357690093, 0.998375839704445, 0.9984986992349847, 0.9984578602883029, 0.997912445377871, 0.998798245765656, 0.7514033846440629, 0.24702584844006717, 0.9982793728068405, 0.9967232053672966, 0.9993621590175157, 0.9983818051137366, 0.9969884587270804, 0.8913822184083534, 0.10700038246140932, 0.9978395743398009, 0.9993336924255203, 0.9988599316108586, 0.3239775132061107, 0.6754036989046518, 0.1789427679947995, 0.6888334509907336, 0.13132090231876414, 0.999149834484795, 0.998207036814389, 0.7802740066860823, 0.1262121220187616, 0.09259487456516623, 0.9989156009941879, 0.9989229144534079, 0.9974935899553212, 0.8028058240425586, 0.11803811659438533, 0.07844769239502628, 0.9977952676780092, 0.9994918502568022, 0.23927527810700577, 0.7597120974469702, 0.9978526773223232, 0.9973097353809275, 0.9985577012322879, 0.9979525998416205, 0.9980305519975385, 0.9979600536627775, 0.9988948381524203, 0.9983578167804188, 0.9966373225672062, 0.998420767207728, 0.9962558596685539, 0.997039175589114, 0.9985926343398979, 0.9978031022110686, 0.9977689794509218, 0.9991792373080135, 0.9999232200031971, 0.9993411260496851, 0.9977706412602064, 0.9992574023373079, 0.20183297554274562, 0.17688022895764874, 0.12855402354600542, 0.10644399492629933, 0.08907182958224455, 0.2969060986074818, 0.9967573712147199, 0.9993276216122432, 0.9978822320965354, 0.1160376726846209, 0.21691727100953906, 0.6659098873883199, 0.9989803271662963, 0.12968014023232238, 0.7496632797998143, 0.12007420391881701, 0.8739365767752307, 0.12509861366548453, 0.744071982368831, 0.2549075741853324, 0.9990101834174571, 0.9973890738717024, 0.9991324421190317, 0.9988355864791674, 0.9974957801568608, 0.9993905335085287, 0.9986977063224847, 0.9979611431680159, 0.9977837347469984, 0.9993522918450262, 0.9997078251338452, 0.1782592514285155, 0.18083898010331312, 0.07507010443661073, 0.07507010443661073, 0.49040642107902743, 0.9977158510349566, 0.9971070732414327, 0.12319057767885136, 0.8743260468888389, 0.9970087900507807, 0.16428751207580927, 0.11300357001221727, 0.12194844362796005, 0.12940250497441239, 0.3637581937068735, 0.07424245101066516, 0.033096032378248326, 0.9980067341160954, 0.26872032686950825, 0.730316551903299, 0.9966695899181257, 0.9973503523536721, 0.045831492943282086, 0.1552784224280651, 0.16743393706833704, 0.2828403795674168, 0.08319669358847595, 0.06021000053333137, 0.15513652926105806, 0.05004099023115836, 0.9969928936261898, 0.9980328784141683, 0.9988505793452499, 0.8787055414348632, 0.12013310432583754, 0.9983176377508881, 0.998682872148549, 0.9982750620993348, 0.9979328850130388, 0.9980853488828317, 0.9986123703947293, 0.9971803368053768, 0.9954561489902058, 0.9964472118238235, 0.9997510982635224, 0.9967158628498292, 0.9988367430411367, 0.4197819794250584, 0.5781542716626941, 0.17848151991678393, 0.7392164500169679, 0.08219370363695437, 0.9976871593776524, 0.998786515051916, 0.9983409905612133, 0.9985515225432495, 0.9982698475554211, 0.28303608725173746, 0.7161206720727885, 0.13283604540388663, 0.19851018625156822, 0.30371633421144645, 0.1381494872200421, 0.07715117517057736, 0.14962652154293793, 0.9980309978622315, 0.3562339064668298, 0.5523140518246352, 0.09089808062944624, 0.9986666798871676, 0.9992306116096004, 0.03923677527563851, 0.14208468622541823, 0.18488844107156932, 0.633138873765985, 0.9977003973371982, 0.19784726371850037, 0.3334194834253279, 0.46788948996380725, 0.9984765945297194, 0.9970424669004935, 0.38665717650756865, 0.06584930805638736, 0.14788426536192875, 0.13128359946536053, 0.10707429503286517, 0.08715349595698327, 0.07373462435725728, 0.9978892130228181, 0.8615701161392278, 0.1370679730221499, 0.9980193686358675, 0.9980686479755457, 0.9967075525077315, 0.9999189779783045, 0.9986391759498549, 0.08773032040518719, 0.20673970241494027, 0.17650327619719325, 0.15311845394997017, 0.2538072427341918, 0.08072976852226053, 0.04125857173554644, 0.9982900265937097, 0.9980624895245739, 0.9993041866237135, 0.9991601924892617, 0.9987404095180626, 0.9988781209321032, 0.9980896952131841, 0.9980759988652325, 0.9991342308392694, 0.9982283638936822, 0.9994949065704732, 0.9991130659514199, 0.9981559767223936, 0.9977402811481677, 0.3777232341173136, 0.2217351408470237, 0.400068635908099, 0.9985711534291372, 0.9989092330431951, 0.9968732519281026, 0.9984419608388047, 0.9973649354365007, 0.9974498757159102, 0.18570792622513443, 0.2419647247233022, 0.5716416621588014, 0.9979976286948096, 0.9980305340595723, 0.9973427438606601, 0.9978611244302831, 0.9977676428589998, 0.9980118828983862, 0.9979646476302273, 0.997379602282478, 0.9973867859021178, 0.9990651177311917, 0.7713659255622011, 0.22746397403739932, 0.997617219161719, 0.9989825127537578, 0.9973884250317006, 0.9973942515898121, 0.9978328841076503, 0.9977882111440736, 0.9987962143184531, 0.9987846910315714, 0.9981778436461787, 0.9991470336528064, 0.9983862819994304, 0.9982531145326978, 0.9987713581500407, 0.99822347661644, 0.998650480691138, 0.9990005499381387, 0.9964031813813479, 0.8650317640210737, 0.13403189151675018, 0.19202178140339574, 0.8073922237260052, 0.9984638850890035, 0.9971251546980411, 0.9983525638623636, 0.9982982899717423, 0.9988858451362794, 0.9984259054011421, 0.8704626745590742, 0.12789257974728993, 0.9975591227614535, 0.9977619228983274, 0.9983454498537826, 0.9972500022337167, 0.9982256289668824, 0.998558837918624, 0.9990284609515001, 0.9968399847419057, 0.998758492981962, 0.9978453342578397, 0.9977643735703692, 0.3453259657771666, 0.6536299241327517, 0.6407076048463713, 0.17043212964282287, 0.18825669334472267, 0.999137348807395, 0.9977995823559285, 0.9978892462185117, 0.3072222181033115, 0.6915713528852786, 0.9981289288152254, 0.9977323626202836, 0.2721222430374187, 0.7268075098847513, 0.34924499187386243, 0.6492919935881025, 0.9974798249054969, 0.9964423065336222, 0.9999006651745366, 0.36109936110447816, 0.6382979675352558, 0.9975223284219202, 0.9991730730086297, 0.9987358985644686, 0.9982170916000225, 0.9976105849527658, 0.9993673459831938, 0.9992231248268293, 0.7896418441874584, 0.20841847932085333, 0.9988084131015061, 0.9982208704025296, 0.9979299623514835, 0.9989703554639586, 0.9985137603551053, 0.24265037908192433, 0.032755646199336144, 0.11830822212786542, 0.07779465972342334, 0.09352598980599926, 0.06120133895139122, 0.1081798315267549, 0.26527763468015, 0.9984328820178718, 0.9976454606679508, 0.9968328010533183, 0.9981813264750942, 0.9976555263059097, 0.9967463659784964, 0.32765598603270985, 0.1436201348469367, 0.11451119629336996, 0.10825638305045479, 0.17513477080162465, 0.10007701188664266, 0.030552356994239464, 0.9997174038046227, 0.9989317967147648, 0.9974728824666721, 0.9971241076201802, 0.9987685637041227, 0.9986039977619039, 0.9992230761043254, 0.1822049757521377, 0.5626807186868402, 0.10641224206271113, 0.14837230909276775, 0.19890707406679028, 0.6125964346845748, 0.1882846892428009, 0.7515564196173828, 0.2470633747247948, 0.7971975067443489, 0.20200768156511478, 0.9972381660702135, 0.9992481336636987, 0.999262050417401, 0.9993801572940922, 0.9977744480292663, 0.21250395764407537, 0.7862646432830789, 0.9989368842909524, 0.6939728371844452, 0.11751836645182084, 0.11137361526479753, 0.0768093898377914, 0.9982855052158077, 0.9975957751924288, 0.8524048809792869, 0.1467603999283657, 0.9980403144578329, 0.9989366877356871, 0.9989601426512462, 0.9979533849650716, 0.9988492131340758, 0.2401383129376187, 0.4960983302415519, 0.1708744071561972, 0.09282066561571206, 0.5402978583525243, 0.17777976893028632, 0.20336928112479724, 0.07833982242003779, 0.11770064017392882, 0.060311614716663305, 0.27073804139330354, 0.08820905764727849, 0.18518588307275033, 0.093522856300729, 0.1838574334093877, 0.9948704311292235, 0.9970553440412611, 0.9971072095218088, 0.29986802044359456, 0.22472190648055948, 0.07610136117442963, 0.39921373042862407, 0.18772767215348593, 0.48801323578683975, 0.209373420514999, 0.11452568678545998, 0.9974897888019553, 0.9991125562456131], \"Term\": [\"action\", \"added\", \"adultsuser\", \"adultsuser\", \"adultsuser\", \"adultsuser\", \"africa\", \"age\", \"age\", \"air\", \"aircraft\", \"airport\", \"allowed\", \"allowed\", \"always\", \"america\", \"america\", \"american\", \"american\", \"americans\", \"amount\", \"ancient\", \"animals\", \"another\", \"another\", \"antenna\", \"anthropology\", \"antibiotics\", \"anyone\", \"architecture\", \"area\", \"area\", \"armenia\", \"armenian\", \"army\", \"around\", \"around\", \"around\", \"around\", \"art\", \"associated\", \"available\", \"average\", \"away\", \"back\", \"back\", \"back\", \"bacteria\", \"battle\", \"begin\", \"believe\", \"believed\", \"besides\", \"big\", \"birds\", \"book\", \"book\", \"born\", \"british\", \"bronx\", \"bronx\", \"call\", \"called\", \"capital\", \"cause\", \"caused\", \"central\", \"century\", \"century\", \"century\", \"century\", \"change\", \"charleston\", \"chat\", \"china\", \"chinese\", \"christian\", \"church\", \"church\", \"city\", \"city\", \"city\", \"city\", \"city\", \"class\", \"college\", \"color\", \"come\", \"common\", \"company\", \"company\", \"company\", \"congress\", \"considered\", \"considered\", \"considered\", \"constitution\", \"could\", \"could\", \"could\", \"could\", \"council\", \"countries\", \"countries\", \"countries\", \"country\", \"country\", \"country\", \"country\", \"country\", \"court\", \"create\", \"created\", \"created\", \"created\", \"created\", \"created\", \"crisis\", \"culture\", \"dame\", \"data\", \"date\", \"date\", \"days\", \"decline\", \"developed\", \"developed\", \"die\", \"diego\", \"discovered\", \"disease\", \"dont\", \"dynasty\", \"early\", \"east\", \"effect\", \"egypt\", \"eisenhower\", \"election\", \"empire\", \"end\", \"end\", \"energy\", \"english\", \"era\", \"europe\", \"europe\", \"european\", \"even\", \"event\", \"ever\", \"everyone\", \"example\", \"federal\", \"field\", \"field\", \"financial\", \"financial\", \"find\", \"first\", \"first\", \"first\", \"first\", \"first\", \"first\", \"food\", \"football\", \"force\", \"forces\", \"form\", \"form\", \"form\", \"form\", \"formed\", \"found\", \"found\", \"found\", \"found\", \"found\", \"founded\", \"france\", \"french\", \"gaddafi\", \"game\", \"general\", \"general\", \"genocide\", \"germany\", \"get\", \"girls\", \"give\", \"given\", \"given\", \"god\", \"good\", \"got\", \"government\", \"government\", \"great\", \"great\", \"great\", \"greece\", \"greek\", \"groups\", \"groups\", \"groups\", \"guys\", \"happened\", \"happens\", \"held\", \"held\", \"held\", \"hello\", \"hey\", \"high\", \"high\", \"highest\", \"hiya\", \"home\", \"hot\", \"human\", \"humanism\", \"hunting\", \"important\", \"india\", \"iran\", \"ireland\", \"islamic\", \"island\", \"japan\", \"japanese\", \"jehovah\", \"join\", \"kind\", \"kingdom\", \"know\", \"known\", \"known\", \"known\", \"known\", \"known\", \"known\", \"land\", \"language\", \"languages\", \"large\", \"large\", \"large\", \"largest\", \"last\", \"last\", \"last\", \"law\", \"law\", \"leader\", \"leader\", \"league\", \"leave\", \"led\", \"leds\", \"level\", \"like\", \"live\", \"lived\", \"lmao\", \"located\", \"lol\", \"long\", \"long\", \"long\", \"long\", \"long\", \"lose\", \"lost\", \"love\", \"love\", \"low\", \"made\", \"made\", \"made\", \"made\", \"made\", \"made\", \"made\", \"majority\", \"make\", \"make\", \"makes\", \"man\", \"many\", \"many\", \"many\", \"many\", \"many\", \"many\", \"many\", \"many\", \"market\", \"mary\", \"mean\", \"members\", \"members\", \"miami\", \"military\", \"minority\", \"mode\", \"model\", \"modern\", \"money\", \"mosaic\", \"movement\", \"much\", \"museum\", \"music\", \"must\", \"must\", \"name\", \"name\", \"name\", \"names\", \"namibia\", \"native\", \"need\", \"neptune\", \"never\", \"never\", \"new\", \"new\", \"new\", \"new\", \"new\", \"new\", \"nice\", \"non\", \"non\", \"non\", \"north\", \"notre\", \"number\", \"number\", \"number\", \"number\", \"occur\", \"often\", \"often\", \"often\", \"old\", \"oldest\", \"one\", \"one\", \"one\", \"one\", \"one\", \"one\", \"one\", \"open\", \"organization\", \"organization\", \"originally\", \"pain\", \"paris\", \"part\", \"party\", \"people\", \"people\", \"people\", \"people\", \"people\", \"people\", \"people\", \"per\", \"percent\", \"percentage\", \"period\", \"place\", \"play\", \"played\", \"player\", \"police\", \"popular\", \"population\", \"portugal\", \"portuguese\", \"position\", \"power\", \"power\", \"power\", \"premier\", \"president\", \"private\", \"process\", \"produce\", \"production\", \"public\", \"public\", \"public\", \"published\", \"punjab\", \"purpose\", \"put\", \"quran\", \"rank\", \"rate\", \"really\", \"receive\", \"red\", \"region\", \"region\", \"related\", \"religion\", \"religions\", \"report\", \"research\", \"responsible\", \"richmond\", \"right\", \"river\", \"roman\", \"rome\", \"room\", \"rule\", \"run\", \"russian\", \"san\", \"santa\", \"say\", \"say\", \"school\", \"school\", \"schools\", \"science\", \"sea\", \"season\", \"see\", \"seen\", \"service\", \"service\", \"side\", \"similar\", \"social\", \"someone\", \"something\", \"song\", \"south\", \"spanish\", \"species\", \"stand\", \"standard\", \"start\", \"start\", \"state\", \"state\", \"state\", \"states\", \"station\", \"status\", \"still\", \"still\", \"stop\", \"street\", \"students\", \"students\", \"study\", \"study\", \"supreme\", \"sure\", \"suser\", \"system\", \"system\", \"systems\", \"take\", \"talk\", \"team\", \"teens\", \"teensuser\", \"term\", \"terms\", \"terms\", \"thanks\", \"thats\", \"theory\", \"think\", \"thought\", \"time\", \"time\", \"time\", \"time\", \"time\", \"time\", \"time\", \"time\", \"today\", \"took\", \"total\", \"translation\", \"tucson\", \"tuvalu\", \"two\", \"two\", \"two\", \"two\", \"two\", \"two\", \"two\", \"type\", \"types\", \"typically\", \"union\", \"united\", \"universities\", \"university\", \"use\", \"use\", \"use\", \"use\", \"used\", \"used\", \"used\", \"using\", \"using\", \"usually\", \"usually\", \"vote\", \"wanna\", \"want\", \"war\", \"washington\", \"water\", \"water\", \"way\", \"well\", \"well\", \"well\", \"well\", \"west\", \"whats\", \"white\", \"white\", \"whitehead\", \"windows\", \"witnesses\", \"women\", \"word\", \"work\", \"work\", \"work\", \"work\", \"world\", \"world\", \"world\", \"world\", \"would\", \"would\", \"would\", \"would\", \"would\", \"would\", \"would\", \"write\", \"wrote\", \"yeah\", \"year\", \"year\", \"year\", \"year\", \"years\", \"years\", \"years\", \"years\", \"yes\", \"youtube\"]}, \"R\": 30, \"lambda.step\": 0.01, \"plot.opts\": {\"xlab\": \"PC1\", \"ylab\": \"PC2\"}, \"topic.order\": [9, 1, 10, 5, 4, 3, 7, 2, 6, 8]};\n",
       "\n",
       "function LDAvis_load_lib(url, callback){\n",
       "  var s = document.createElement('script');\n",
       "  s.src = url;\n",
       "  s.async = true;\n",
       "  s.onreadystatechange = s.onload = callback;\n",
       "  s.onerror = function(){console.warn(\"failed to load library \" + url);};\n",
       "  document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "}\n",
       "\n",
       "if(typeof(LDAvis) !== \"undefined\"){\n",
       "   // already loaded: just create the visualization\n",
       "   !function(LDAvis){\n",
       "       new LDAvis(\"#\" + \"ldavis_el1404427492905800009913921335\", ldavis_el1404427492905800009913921335_data);\n",
       "   }(LDAvis);\n",
       "}else if(typeof define === \"function\" && define.amd){\n",
       "   // require.js is available: use it to load d3/LDAvis\n",
       "   require.config({paths: {d3: \"https://d3js.org/d3.v5\"}});\n",
       "   require([\"d3\"], function(d3){\n",
       "      window.d3 = d3;\n",
       "      LDAvis_load_lib(\"https://cdn.jsdelivr.net/gh/bmabey/pyLDAvis@3.4.0/pyLDAvis/js/ldavis.v3.0.0.js\", function(){\n",
       "        new LDAvis(\"#\" + \"ldavis_el1404427492905800009913921335\", ldavis_el1404427492905800009913921335_data);\n",
       "      });\n",
       "    });\n",
       "}else{\n",
       "    // require.js not available: dynamically load d3 & LDAvis\n",
       "    LDAvis_load_lib(\"https://d3js.org/d3.v5.js\", function(){\n",
       "         LDAvis_load_lib(\"https://cdn.jsdelivr.net/gh/bmabey/pyLDAvis@3.4.0/pyLDAvis/js/ldavis.v3.0.0.js\", function(){\n",
       "                 new LDAvis(\"#\" + \"ldavis_el1404427492905800009913921335\", ldavis_el1404427492905800009913921335_data);\n",
       "            })\n",
       "         });\n",
       "}\n",
       "</script>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pyLDAvis.gensim_models as gensimvis\n",
    "import pyLDAvis\n",
    "vis_data = gensimvis.prepare(lda, corpus, dictionary, mds='tsne')\n",
    "panel = pyLDAvis.display(vis_data)\n",
    "panel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# sentence embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "train_sentences, test_sentences = train_test_split(data_lemmatized, test_size=0.2, random_state=42)\n",
    "\n",
    "# Tag the sentences\n",
    "tagged_train_sentences = [TaggedDocument(words=sent.split(), tags=[i]) for i, sent in enumerate(train_sentences)]\n",
    "tagged_test_sentences = [TaggedDocument(words=sent.split(), tags=[i]) for i, sent in enumerate(test_sentences)]\n",
    "\n",
    "# Initialize the model\n",
    "model = Doc2Vec(vector_size=50, min_count=2, epochs=40)\n",
    "\n",
    "# Build the vocabulary\n",
    "model.build_vocab(tagged_train_sentences)\n",
    "\n",
    "# Train the model\n",
    "model.train(tagged_train_sentences, total_examples=model.corpus_count, epochs=model.epochs)\n",
    "\n",
    "# Now you can use the trained model to convert sentences into vectors\n",
    "train_vectors = [model.infer_vector(sent.split()) for sent in train_sentences]\n",
    "test_vectors = [model.infer_vector(sent.split()) for sent in test_sentences]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# word embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape after tokenization (X_train_t): (176332, 250)\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(sentences_train)\n",
    "\n",
    "X_train_t = tokenizer.texts_to_sequences(sentences_train)\n",
    "X_test_t = tokenizer.texts_to_sequences(sentences_test)\n",
    "\n",
    "\n",
    "\n",
    "vocab_size = len(tokenizer.word_index) + 1  # Adding 1 because of reserved 0 index\n",
    "maxlen = 250  # Fixed the maxlen value\n",
    "\n",
    "X_train_t = pad_sequences(X_train_t, padding='post', maxlen=maxlen)\n",
    "X_test_t = pad_sequences(X_test_t, padding='post', maxlen=maxlen)\n",
    "encoder = LabelEncoder()\n",
    "encoder.fit(y_train)\n",
    "y_test_t = encoder.fit_transform(y_test)\n",
    "y_train_t = encoder.fit_transform(y_train)\n",
    "\n",
    "\n",
    "\n",
    "print(\"Shape after tokenization (X_train_t):\", X_train_t.shape)\n",
    "\n",
    "\n",
    "# Assuming that `y_test` is your list of labels\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 0, ..., 0, 0, 1])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test_t"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7768722991595495 ['sentence']\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "lr_pipeline = Pipeline([\n",
    "    ('vect', TfidfVectorizer(stop_words='english', ngram_range=(1, 2))),\n",
    "    ('clf', LogisticRegression(C=1.0, class_weight='balanced')),\n",
    "])\n",
    "\n",
    "lr_pipeline.fit(sentences_train, y_train)\n",
    "print(lr_pipeline.score(sentences_test, y_test),lr_pipeline.predict([\"this is good\"]))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random forest classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7558270101058219 ['question']\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rf_pipeline = Pipeline([\n",
    "    ('vect', CountVectorizer()),\n",
    "    ('clf', RandomForestClassifier(max_depth=15, n_estimators=40)),\n",
    "])\n",
    "rf_pipeline.fit(sentences_train, y_train)\n",
    "print(rf_pipeline.score(sentences_test, y_test),rf_pipeline.predict([\"is this good?\"]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Tree Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9659396372792541 ['sentence']\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "dt_pipeline = Pipeline([\n",
    "    ('vect', CountVectorizer()),\n",
    "    ('clf', DecisionTreeClassifier(max_depth=25)),\n",
    "])\n",
    "dt_pipeline.fit(sentences_train, y_train)\n",
    "print(dt_pipeline.score(sentences_test, y_test),dt_pipeline.predict([\"this is good\"])\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9819150022117119 ['sentence']\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "svm_pipeline = Pipeline([\n",
    "    ('vect', CountVectorizer()),\n",
    "    ('clf', SVC(kernel='rbf', C=1.0, gamma='scale')),\n",
    "])\n",
    "svm_pipeline.fit(sentences_train, y_train)\n",
    "print(svm_pipeline.score(sentences_test, y_test),svm_pipeline.predict([\"this is good\"]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# plot curve (please run it once because i made changes in this but did not have enough time to run it since begining. the code gives the graph, kindly run it once)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve, auc\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "y_pred_dt = dt_pipeline.predict_proba(sentences_test)[:, 1]\n",
    "fpr_dt, tpr_dt, thresholds_dt = roc_curve(y_test, y_pred_dt,pos_label=\"sentence\")\n",
    "auc_dt = auc(fpr_dt, tpr_dt)\n",
    "\n",
    "y_pred_rf = rf_pipeline.predict_proba(sentences_test)[:, 1]\n",
    "fpr_rf, tpr_rf, thresholds_rf = roc_curve(y_test, y_pred_rf,pos_label=\"sentence\")\n",
    "auc_rf = auc(fpr_rf, tpr_rf)\n",
    "\n",
    "y_pred_lr = lr_pipeline.predict_proba(sentences_test)[:, 1]\n",
    "fpr_lr, tpr_lr, thresholds_lr = roc_curve(y_test, y_pred_lr,pos_label=\"sentence\")\n",
    "auc_lr = auc(fpr_lr, tpr_lr)\n",
    "\n",
    "\n",
    "y_pred_svc = svm_pipeline.decision_function(sentences_test)\n",
    "fpr_svc, tpr_svc, thresholds_svc = roc_curve(y_test, y_pred_svc,pos_label=\"sentence\")\n",
    "auc_svc = auc(fpr_lr, tpr_lr)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "plt.figure(1)\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "plt.plot(fpr_svc, tpr_svc, label='svc (area = {:.3f})'.format(auc_svc))\n",
    "plt.plot(fpr_rf, tpr_rf, label='RF (area = {:.3f})'.format(auc_rf))\n",
    "plt.plot(fpr_lr, tpr_lr, label='LR (area = {:.3f})'.format(auc_lr))\n",
    "plt.plot(fpr_dt, tpr_dt, label='DT (area = {:.3f})'.format(auc_dt))\n",
    "plt.xlabel('False positive rate')\n",
    "plt.ylabel('True positive rate')\n",
    "plt.title('ROC curve')\n",
    "plt.legend(loc='best')\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current directory: c:\\Users\\manoj\\Downloads\\Ml\n",
      "Files in current directory: ['Assignment 4_ML.ipynb', 'desktop.ini', 'Dockerfile', 'nlp dataset.csv']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Get the current directory\n",
    "current_dir = os.getcwd()\n",
    "\n",
    "# List all files in the current directory\n",
    "files = os.listdir(current_dir)\n",
    "\n",
    "print(\"Current directory:\", current_dir)\n",
    "print(\"Files in current directory:\", files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from tensorflow.keras.models import save_model\n",
    "import joblib\n",
    "import pickle\n",
    "\n",
    "# Specify the path to the directory where you want to save the models\n",
    "dir_path = 'C:\\\\Users\\\\manoj\\\\Downloads'\n",
    "\n",
    "# Create the directory if it doesn't exist\n",
    "os.makedirs(dir_path, exist_ok=True)\n",
    "\n",
    "\n",
    "with open(os.path.join(dir_path, 'lr_pipeline.pkl'), 'wb') as f:\n",
    "    pickle.dump(lr_pipeline, f)\n",
    "\n",
    "with open(os.path.join(dir_path, 'dt_pipeline.pkl'), 'wb') as f:\n",
    "    pickle.dump(dt_pipeline, f)\n",
    "\n",
    "with open(os.path.join(dir_path, 'rf_pipeline.pkl'), 'wb') as f:\n",
    "    pickle.dump(rf_pipeline, f)\n",
    "\n",
    "# with open(os.path.join(dir_path, 'svc.pkl'), 'wb') as f:\n",
    "    # pickle.dump(svm_pipeline, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the path to the directory where you want to save the models\n",
    "dir_path = 'C:\\\\Users\\\\manoj\\\\Downloads'\n",
    "\n",
    "# Create the directory if it doesn't exist\n",
    "os.makedirs(dir_path, exist_ok=True)\n",
    "\n",
    "with open(os.path.join(dir_path, 'vectorizer.pkl'), 'wb') as f:\n",
    "    pickle.dump(vectorizer, f)\n",
    "\n",
    "with open(os.path.join(dir_path, 'tfidf_vectorizer.pkl'), 'wb') as f:\n",
    "    pickle.dump(tfidf_vectorizer, f)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Serving Flask app '__main__'\n",
      " * Debug mode: off\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\n",
      " * Running on http://127.0.0.1:5000\n",
      "Press CTRL+C to quit\n"
     ]
    }
   ],
   "source": [
    "from flask import Flask, request, jsonify\n",
    "import requests\n",
    "import json\n",
    "import torch\n",
    "from tensorflow.keras.models import load_model\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from gensim import models\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "\n",
    "app = Flask(__name__)\n",
    "\n",
    "\n",
    "lr_pipeline = joblib.load('C:\\\\Users\\\\manoj\\\\Downloads\\\\lr_pipeline.pkl')\n",
    "dt_pipeline = joblib.load('C:\\\\Users\\\\manoj\\\\Downloads\\\\dt_pipeline.pkl')\n",
    "rf_pipeline = joblib.load('C:\\\\Users\\\\manoj\\\\Downloads\\\\rf_pipeline.pkl')\n",
    "# svm_pipeline= joblib.load('C:\\\\Users\\\\manoj\\\\Downloads\\\\svm_pipeline.pkl')\n",
    "\n",
    "# Load your vectorizers\n",
    "vectorizer = joblib.load('C:\\\\Users\\\\manoj\\\\Downloads\\\\vectorizer.pkl')\n",
    "tfidf_vectorizer = joblib.load('C:\\\\Users\\\\manoj\\\\Downloads\\\\tfidf_vectorizer.pkl')\n",
    "\n",
    "\n",
    "@app.route('/')\n",
    "def home():\n",
    "    return \"Hello, World!\"\n",
    "\n",
    "@app.route('/predict', methods=['POST'])\n",
    "\n",
    "\n",
    "def predict():\n",
    "    data = request.get_json(force=True)\n",
    "    text = data['text']\n",
    "    model = data.get('model', 'lr') \n",
    "    # model = data.get('model', 'lr')\n",
    "\n",
    "    # Vectorize the input text\n",
    "    text_vector = vectorizer.transform([text])\n",
    "    text_tfidf = tfidf_vectorizer.transform([text])\n",
    "    text_lsa = lsa_obj.transform(text_tfidf)\n",
    "    text_lda = lda[text_vector]\n",
    "\n",
    "    # Make predictions using your models\n",
    "    if model == 'lr':\n",
    "        prediction = lr_pipeline.predict(text_vector)\n",
    "    elif model == 'dt':\n",
    "        prediction = dt_pipeline.predict(text_vector)\n",
    "    elif model == 'rf':\n",
    "        prediction = rf_pipeline.predict(text_vector)\n",
    "    elif model == 'svc':\n",
    "        prediction = svm_pipeline.predict(text_vector)\n",
    "    else:\n",
    "        return jsonify({'error': 'Invalid model specified'}), 400\n",
    "\n",
    "    # Return the predictions as JSON\n",
    "    return jsonify({\n",
    "        'prediction': prediction.tolist()\n",
    "    })\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    app.run()\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
